{
  "ticker": "AMD",
  "company": "Advanced Micro Devices",
  "sector": "Tech",
  "fiscal_year": "2025",
  "fiscal_quarter": "Q4",
  "speaker": "LISA  SU",
  "doc_path": "data/raw/AMD_2025Q4_Transcript.pdf",
  "segment_index": 40,
  "kpis": {
    "revenue_growth_yoy_pct": null,
    "eps_growth_yoy_pct": null,
    "guidance_comment": null,
    "margin_comment": null
  },
  "sentiment": {
    "polarity": 0.14662143412143414,
    "subjectivity": 0.3533265345765345
  },
  "text_preview": "Yeah, Antoine, thanks for the question. I think the answer is yes. I think all of our large customers contribute to,\n\nlet's call it, a broadening and deepening of our software stack. Overall, I think the relationship with OpenAI is\n\ncertainly one where our plans are to work deeply together on hardware as well as software as well as systems\n\nand future roadmap. And from that standpoint, the work that we're doing together with them on Triton is-- it's\n\ncertainly very valuable.\n\nBut I will say, beyond OpenAI, the work that we do with all of our largest customers are super helpful to\n\nstrengthening the software stack. And we have put significant new resources into not just the largest customers,\n\nbut we are working with a broad set of AI native companies who are actively developing on the ROCm stack. We\n\nget lots of feedback. I think we've made significant progress in the training and inference stack. And we're going\n\nto continue to double down and triple down in this area.\n\nSo the more customers that use AMD, I think all of that goes to enhancing the ROCm stack. And, we're actually--\n\nwe'll talk a little bit more about this next week, but we're also using AI to help us accelerate the rate and pace of\n\nsome of the ROCm kernel development, and just the overall ecosystem.\n\nANTOINE\n\nThanks, Lisa. Maybe as a quick follow-up, could you tell us about the useful lives of GPUs? I know that most CSPs"
}